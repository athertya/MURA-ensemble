{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "#from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, image\n",
    "from keras.applications.densenet import DenseNet169\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Utility function to find the list of files in a directory excluding the hidden files.\n",
    "# def listdir_nohidden(path):\n",
    "#     for f in os.listdir(path):\n",
    "#         if not f.startswith('.'):\n",
    "#             yield f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     image_data = {}\n",
    "#     study_label = {'positive': 1, 'negative': 0}\n",
    "#     category = 'train'\n",
    "#     study_types = ['XR_ELBOW']\n",
    "#     #study_types = ['XR_ELBOW','XR_FINGER','XR_FOREARM','XR_HAND','XR_HUMERUS','XR_SHOULDER','XR_WRIST']\n",
    "   \n",
    "#     i = 0\n",
    "#     image_data[category] = pd.DataFrame(columns=['Path','Label'])\n",
    "#     for study_type in study_types: # Iterate throught every study types\n",
    "#         DATA_DIR = 'MURA-v1.1/%s/%s/' % (category, study_type)\n",
    "#         patients = list(os.walk(DATA_DIR))[0][1]  # list of patient folder names\n",
    "#         for patient in tqdm(patients):  # for each patient folder\n",
    "#             for study in os.listdir(DATA_DIR + patient):  # for each study in that patient folder\n",
    "#                 if(study != '.DS_Store'):\n",
    "#                     label = study_label[study.split('_')[1]]  # get label 0 or 1\n",
    "#                     path = DATA_DIR + patient + '/' + study + '/'  # path to this study\n",
    "#                     for j in range(len(list(listdir_nohidden(path)))):\n",
    "#                         image_path = path + 'image%s.png' % (j + 1)\n",
    "#                         image_data[category].loc[i] = [image_path,label]  # add new row\n",
    "#                         i += 1\n",
    "#     image_data[category].to_csv(category+\"_image_data.csv\",index = None, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(category,study_type):\n",
    "    image_data = {}\n",
    "    study_label = {'positive': 1, 'negative': 0}\n",
    "    #study_types = ['XR_ELBOW','XR_FINGER','XR_FOREARM','XR_HAND','XR_HUMERUS','XR_SHOULDER','XR_WRIST']\n",
    "   \n",
    "    i = 0\n",
    "    image_data[category] = pd.DataFrame(columns=['Path','Label'])\n",
    "    for study_type in study_types: # Iterate throught every study types\n",
    "        DATA_DIR = 'MURA-v1.1/%s/%s/' % (category, study_type)\n",
    "        patients = list(os.walk(DATA_DIR))[0][1]\n",
    "        #print(\"Patient data - \", patients)# list of patient folder names\n",
    "        for patient in tqdm(patients):  # for each patient folder\n",
    "            for study in os.listdir(DATA_DIR + patient):\n",
    "                #print('Study split',study.split('_')[1])\n",
    "                label = study_label[study.split('_')[1]]  # get label 0 or 1\n",
    "                path = DATA_DIR + patient + '/' + study + '/'  # path to this study\n",
    "                for j in range(len(list(os.listdir(path)))):\n",
    "                    #print(list(os.listdir(path)))\n",
    "                    image_path = path + 'image%s.png' % (j + 1)\n",
    "                    image_data[category].loc[i] = [image_path,label]  # add new row\n",
    "                    i += 1\n",
    "    image_data[category].to_csv(category+\"_image_data_test.csv\",index = None, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImagesInArrayNew(train_dataframe):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i, data in tqdm(train_dataframe.iterrows()):\n",
    "        #print('This is number of image',i,data)\n",
    "        img = cv2.imread(data['Path'])\n",
    "        img = cv2.resize(img,(img_width,img_height))    \n",
    "        #plt.imshow(img)\n",
    "        images.append(img)\n",
    "        labels.append(data['Label'])\n",
    "    images = np.asarray(images).astype('float32') \n",
    "    #normalization\n",
    "    mean = np.mean(images[:, :, :])\n",
    "    std = np.std(images[:, :, :])\n",
    "    images[:, :, :] = (images[:, :, :] - mean) / std\n",
    "    labels = np.asarray(labels)\n",
    "    return {'images': images, 'labels': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_image_df = pd.read_csv('train_image_data_test.csv', names=['Path', 'Label'])\n",
    "# print(train_image_df.head())\n",
    "# dd={}\n",
    "\n",
    "# img_width, img_height = 224, 224\n",
    "# dd['train'] = train_image_df\n",
    "# #print(dd)\n",
    "# train_dict = getImagesInArrayNew(train_image_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 123.73it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 150.13it/s]\n",
      "50it [00:00, 151.81it/s]\n",
      "81it [00:00, 168.78it/s]\n"
     ]
    }
   ],
   "source": [
    "#train_data_dir = 'train/XR_ELBOW'\n",
    "#valid_data_dir = 'valid/XR_ELBOW'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    horizontal_flip=True\n",
    "\n",
    ")\n",
    "\n",
    "study_types = ['XR_ELBOW_test']\n",
    "\n",
    "data_loader('train',study_types)\n",
    "data_loader('valid',study_types)\n",
    "\n",
    "\n",
    "train_image_df = pd.read_csv('train_image_data_test.csv', names=['Path','Label'])\n",
    "valid_image_df = pd.read_csv('valid_image_data_test.csv', names=['Path','Label'])\n",
    "\n",
    "dd={}\n",
    "\n",
    "dd['train'] = train_image_df\n",
    "dd['valid'] = valid_image_df\n",
    "\n",
    "\n",
    "train_dict = getImagesInArrayNew(train_image_df)\n",
    "valid_dict = getImagesInArrayNew(valid_image_df)\n",
    "\n",
    "train_datagen.fit(train_dict['images'],augment=True)\n",
    "valid_datagen.fit(valid_dict['images'],augment=True)\n",
    "\n",
    "train_generator = train_datagen.flow(\n",
    "    x=train_dict['images'],\n",
    "    y=train_dict['labels']\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow(\n",
    "    x=valid_dict['images'],\n",
    "    y=valid_dict['labels'],\n",
    "    batch_size = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training samples 50\n",
      "Length of validation samples 81\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#model parameters for training\n",
    "#K.set_learning_phase(1)\n",
    "nb_train_samples = len(train_dict['images'])\n",
    "print('Length of training samples',len(train_dict['images']))\n",
    "nb_validation_samples = len(valid_dict['images'])\n",
    "print('Length of validation samples',len(valid_dict['images']))\n",
    "epochs = 2\n",
    "batch_size = 8\n",
    "steps_per_epoch = nb_train_samples//batch_size\n",
    "print(steps_per_epoch)\n",
    "n_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    base_model = DenseNet169(input_shape=(None, None,3),\n",
    "                             weights='imagenet',\n",
    "                             include_top=False,\n",
    "                             pooling='avg')\n",
    "\n",
    "    x = base_model.output\n",
    "    predictions = Dense(n_classes,activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the model\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['acc', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks for early stopping incase of reduced learning rate, loss unimprovement\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=8, verbose=1, min_delta=1e-4)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, verbose=1, min_lr=0.0001)\n",
    "callbacks_list = [early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "6/6 [==============================] - 399s 67s/step - loss: 0.5616 - acc: 0.6894 - mean_squared_error: 0.1942 - val_loss: 1.7324 - val_acc: 0.5000 - val_mean_squared_error: 0.4371\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 687s 115s/step - loss: 0.4748 - acc: 0.8608 - mean_squared_error: 0.1208 - val_loss: 2.9261 - val_acc: 0.4000 - val_mean_squared_error: 0.5262\n"
     ]
    }
   ],
   "source": [
    "#train the module\n",
    "model_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    workers=0,\n",
    "    use_multiprocessing=False,  \n",
    "    steps_per_epoch = nb_train_samples//batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples //batch_size,\n",
    "    #callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
